{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>[Training] - FastAI Baseline</h1>\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T21:17:17.164466Z",
     "iopub.status.busy": "2022-06-22T21:17:17.163998Z",
     "iopub.status.idle": "2022-06-22T21:17:17.295969Z",
     "shell.execute_reply": "2022-06-22T21:17:17.292799Z",
     "shell.execute_reply.started": "2022-06-22T21:17:17.164418Z"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"https://hubmapconsortium.org/wp-content/uploads/2019/01/HuBMAP-Retina-Logo-Color.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011984,
     "end_time": "2021-03-11T18:12:50.627613",
     "exception": false,
     "start_time": "2021-03-11T18:12:50.615629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description \n",
    "\n",
    "Welcome to Human BioMolecular Atlas Program (HuBMAP) + Human Protein Atlas (HPA) competition. \n",
    "The objective of this challenge is segmentation of functional tissue units (FTU. e.g., glomeruli in kidney or alveoli in the lung) in biopsy slides from several different organs. \n",
    "The underlying data includes imagery from different sources prepared with different protocols at a variety of resolutions, reflecting typical challenges for working with medical data.\n",
    "\n",
    "This notebook provides a fast.ai starter Pytorch code based on a U-shape network (UneXt50) that was used on multiple competitions in the past and includes several tricks from the previous segmentation competitions.\n",
    "It is [dividing the images into tiles](https://www.kaggle.com/code/thedevastator/converting-to-256x256), selection of tiles with tissue, evaluation of the predictions of multiple models with TTA, combining the tile masks back into image level masks, and conversion into RLE. The [inference](https://www.kaggle.com/code/thedevastator/inference-fastai-baseline) is performed based on models trained in the [fast.ai training notebook](https://www.kaggle.com/code/thedevastator/training-fastai-baseline).\n",
    "\n",
    "**Inference & Dataset Creation**\n",
    "\n",
    "- #### Inference Notebook [here](https://www.kaggle.com/code/thedevastator/inference-fastai-baseline). \n",
    "- #### Dataset Creation [here](https://www.kaggle.com/code/thedevastator/converting-to-256x256). \n",
    "\n",
    "**Precomputed Datasets**\n",
    "\n",
    "- ##### [Dataset (512 x 512)](https://www.kaggle.com/datasets/thedevastator/hubmap-2022-512x512/)\n",
    "\n",
    "- ##### [Dataset (256 x 256)](https://www.kaggle.com/datasets/thedevastator/hubmap-2022-256x256/)\n",
    "\n",
    "- ##### [Dataset (128 x 128)](https://www.kaggle.com/datasets/thedevastator/hubmap-2022-128x128/settings)\n",
    "\n",
    "____\n",
    "\n",
    "#### Everything is based on the excellent [notebooks](https://www.kaggle.com/code/iafoss/hubmap-pytorch-fast-ai-starter) by [iafoss](https://www.kaggle.com/iafoss) \n",
    "All credit to belongs to the original author!\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lovasz-Softmax and Jaccard hinge loss in PyTorch\n",
    "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse\n",
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n",
    "    \"\"\"\n",
    "    IoU for foreground class\n",
    "    binary: 1 foreground, 0 background\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        intersection = ((label == 1) & (pred == 1)).sum()\n",
    "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n",
    "        if not union:\n",
    "            iou = EMPTY\n",
    "        else:\n",
    "            iou = float(intersection) / union\n",
    "        ious.append(iou)\n",
    "    iou = f_mean(ious)    # mean accross images if per_image\n",
    "    return 100 * iou\n",
    "\n",
    "\n",
    "def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n",
    "    \"\"\"\n",
    "    Array of IoU for each (non ignored) class\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        iou = []    \n",
    "        for i in range(C):\n",
    "            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n",
    "                intersection = ((label == i) & (pred == i)).sum()\n",
    "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n",
    "                if not union:\n",
    "                    iou.append(EMPTY)\n",
    "                else:\n",
    "                    iou.append(float(intersection) / union)\n",
    "        ious.append(iou)\n",
    "    ious = map(f_mean, zip(*ious)) # mean accross images if per_image\n",
    "    return 100 * np.array(ious)\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = f_mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
    "                          for log, lab in zip(logits, labels))\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * Variable(signs))\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    #loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "    loss = torch.dot(F.elu(errors_sorted)+1, Variable(grad))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "class StableBCELoss(torch.nn.modules.Module):\n",
    "    def __init__(self):\n",
    "         super(StableBCELoss, self).__init__()\n",
    "    def forward(self, input, target):\n",
    "         neg_abs = - input.abs()\n",
    "         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "         return loss.mean()\n",
    "\n",
    "\n",
    "def binary_xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Cross entropy loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    logits, labels = flatten_binary_scores(logits, labels, ignore)\n",
    "    loss = StableBCELoss()(logits, Variable(labels.float()))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --------------------------- MULTICLASS LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_softmax(probas, labels, only_present=False, per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = f_mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), only_present=only_present)\n",
    "                          for prob, lab in zip(probas, labels))\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), only_present=only_present)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, only_present=False):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "    \"\"\"\n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    for c in range(C):\n",
    "        fg = (labels == c).float() # foreground for class c\n",
    "        if only_present and fg.sum() == 0:\n",
    "            continue\n",
    "        errors = (Variable(fg) - probas[:, c]).abs()\n",
    "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
    "        perm = perm.data\n",
    "        fg_sorted = fg[perm]\n",
    "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n",
    "    return f_mean(losses)\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    B, C, H, W = probas.size()\n",
    "    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = (labels != ignore)\n",
    "    vprobas = probas[valid.nonzero().squeeze()]\n",
    "    vlabels = labels[valid]\n",
    "    return vprobas, vlabels\n",
    "\n",
    "def xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Cross entropy loss\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n",
    "\n",
    "\n",
    "# --------------------------- HELPER FUNCTIONS ---------------------------\n",
    "\n",
    "def f_mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(np.isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 3.556569,
     "end_time": "2021-03-11T18:12:54.195121",
     "exception": false,
     "start_time": "2021-03-11T18:12:50.638552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn as nn\n",
    "from fastai.vision.all import PixelShuffle_ICNR, ConvLayer, Tensor, Metric, flatten_check\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import random\n",
    "from albumentations import *\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isdir, isfile, join\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.045568,
     "end_time": "2021-03-11T18:12:54.252135",
     "exception": false,
     "start_time": "2021-03-11T18:12:54.206567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../hubmap-organ-segmentation/hubmap-2022-256x256/image/ True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SEED = 2021\n",
    "TRAIN = '../input/hubmap-2022-256x256/train/'\n",
    "MASKS = '../input/hubmap-2022-256x256/masks/'\n",
    "LABELS = '../input/hubmap-organ-segmentation/train.csv'\n",
    "SAVE_FILE = \"../working/best_model\"\n",
    "if not isdir(TRAIN):\n",
    "    TRAIN = '../../hubmap-organ-segmentation/hubmap-2022-256x256/image/'\n",
    "    MASKS = '../../hubmap-organ-segmentation/hubmap-2022-256x256/mask/'\n",
    "    LABELS = '../../hubmap-organ-segmentation/train.csv'\n",
    "    SAVE_FILE = \"best_model\"\n",
    "    BATCH_SIZE=4\n",
    "    train_ids = [10044, 10274, 10666, 10912, 10971, 1184, 12233, 12244, 1229, 13483, 13942, 14396, 14407, 1500, 15706, 15732, 16149, 16609, 16659, 1690, 17143, 17187, 17455, 17828, 18422, 19084, 1955, 19569, 20247, 20428, 20955, 21086, 21155, 2174, 22016, 22059, 22995, 23009, 23640, 23828, 23959, 23961, 24194, 24269, 24961, 25430, 26982, 27471, 28318, 28622, 29213, 29223, 29296, 29307, 29809, 30080, 30294, 30355, 30414, 30424, 30765, 31898, 31958, 32009, 32126, 32412, 32741, 3409, 435, 4639, 4658, 4802, 4944, 5287, 5317, 5785, 5932, 5995, 6120, 10392, 10610, 10703, 10992, 1123, 11448, 11645, 12026, 12466, 12483, 144, 15551, 18792, 19179, 19360, 19377, 19507, 19997, 2079, 20831, 21358, 22236, 2279, 22953, 24833, 25472, 26664, 27781, 27803, 28126, 28657, 28748, 28963, 29143, 29690, 30201, 3054, 3057, 30581, 31290, 31675, 31733, 32231, 3959, 4404, 10488, 11064, 11629, 1220, 12452, 12476, 127, 12827, 13189, 14388, 15067, 15124, 15329, 16564, 1731, 1878, 20563, 23252, 24782, 25516, 25945, 26480, 27232, 2793, 28052, 28189, 28429, 29610, 30084, 30394, 30500, 31139, 31571, 31800, 32151, 4301, 4412, 4776, 5086, 5552, 10611, 11497, 1157, 12784, 13034, 13260, 14756, 15005, 15192, 15787, 15860, 16163, 16214, 16216, 16362, 164, 16711, 17422, 18121, 18401, 18426, 18449, 18777, 19048, 19533, 20302, 20440, 20478, 20520, 20794, 21021, 21112, 21129, 21195, 21321, 22035, 22133, 22544, 22718, 22741, 23051, 23243, 2344, 23665, 23760, 23880, 24097, 24100, 24222, 2424, 24241, 2447, 24522, 2500, 25620, 26101, 26174, 2668, 27298, 27350, 27468, 27616, 27879, 28262, 28436, 2874, 28823, 28940, 29238, 2943, 30194, 30224, 30250, 30474, 3083, 30876, 31698, 31709, 32325, 32527, 4066, 4265, 4777, 5099, 10651, 10892, 11662, 1168, 11890, 12174, 12471, 13396, 13507, 14183, 14674, 15499, 15842, 16728, 16890, 17126, 18445, 1850, 18900, 203, 21039, 21501, 21812, 22310, 23094, 25298, 25641, 25689, 26319, 26780, 26886, 2696, 27128, 27340, 27587, 27861, 28045, 28791, 29180, 29424, 29820, 31406, 31727, 31799, 3303, 351, 4062, 4561, 5832]\n",
    "    val_ids = [6390, 6730, 6794, 737, 7397, 7706, 7902, 8227, 8388, 8638, 8842, 9231, 928, 9358, 5583, 6722, 7169, 8116, 8876, 8894, 9407, 9453, 5777, 686, 7359, 8151, 8231, 8343, 9387, 9450, 5102, 6021, 62, 6318, 660, 6807, 7569, 7970, 8502, 9437, 9445, 9470, 9517, 9769, 9791, 6121, 6611, 676, 8222, 8402, 8450, 8752, 9777, 9904]     \n",
    "else:\n",
    "    BATCH_SIZE=32\n",
    "    train_ids = [10044, 10274, 10666, 10912, 10971, 1184, 12233, 12244, 1229, 13483, 13942, 14396, 14407, 1500, 15706, 15732, 16149, 16609, 16659, 1690, 17143, 17187, 17455, 17828, 18422, 19084, 1955, 19569, 20247, 20428, 20955, 21086, 21155, 2174, 22016, 22059, 22995, 23009, 23640, 23828, 23959, 23961, 24194, 24269, 24961, 25430, 26982, 27471, 28318, 28622, 29213, 29223, 29296, 29307, 29809, 30080, 30294, 30355, 30414, 30424, 30765, 31898, 31958, 32009, 32126, 32412, 32741, 3409, 435, 4639, 4658, 4802, 4944, 5287, 5317, 5785, 5932, 5995, 6120, 10392, 10610, 10703, 10992, 1123, 11448, 11645, 12026, 12466, 12483, 144, 15551, 18792, 19179, 19360, 19377, 19507, 19997, 2079, 20831, 21358, 22236, 2279, 22953, 24833, 25472, 26664, 27781, 27803, 28126, 28657, 28748, 28963, 29143, 29690, 30201, 3054, 3057, 30581, 31290, 31675, 31733, 32231, 3959, 4404, 10488, 11064, 11629, 1220, 12452, 12476, 127, 12827, 13189, 14388, 15067, 15124, 15329, 16564, 1731, 1878, 20563, 23252, 24782, 25516, 25945, 26480, 27232, 2793, 28052, 28189, 28429, 29610, 30084, 30394, 30500, 31139, 31571, 31800, 32151, 4301, 4412, 4776, 5086, 5552, 10611, 11497, 1157, 12784, 13034, 13260, 14756, 15005, 15192, 15787, 15860, 16163, 16214, 16216, 16362, 164, 16711, 17422, 18121, 18401, 18426, 18449, 18777, 19048, 19533, 20302, 20440, 20478, 20520, 20794, 21021, 21112, 21129, 21195, 21321, 22035, 22133, 22544, 22718, 22741, 23051, 23243, 2344, 23665, 23760, 23880, 24097, 24100, 24222, 2424, 24241, 2447, 24522, 2500, 25620, 26101, 26174, 2668, 27298, 27350, 27468, 27616, 27879, 28262, 28436, 2874, 28823, 28940, 29238, 2943, 30194, 30224, 30250, 30474, 3083, 30876, 31698, 31709, 32325, 32527, 4066, 4265, 4777, 5099, 10651, 10892, 11662, 1168, 11890, 12174, 12471, 13396, 13507, 14183, 14674, 15499, 15842, 16728, 16890, 17126, 18445, 1850, 18900, 203, 21039, 21501, 21812, 22310, 23094, 25298, 25641, 25689, 26319, 26780, 26886, 2696, 27128, 27340, 27587, 27861, 28045, 28791, 29180, 29424, 29820, 31406, 31727, 31799, 3303, 351, 4062, 4561, 5832]\n",
    "    val_ids = [6390, 6730, 6794, 737, 7397, 7706, 7902, 8227, 8388, 8638, 8842, 9231, 928, 9358, 5583, 6722, 7169, 8116, 8876, 8894, 9407, 9453, 5777, 686, 7359, 8151, 8231, 8343, 9387, 9450, 5102, 6021, 62, 6318, 660, 6807, 7569, 7970, 8502, 9437, 9445, 9470, 9517, 9769, 9791, 6121, 6611, 676, 8222, 8402, 8450, 8752, 9777, 9904]     \n",
    "    train_ids = train_ids + val_ids\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "print(TRAIN, isdir(TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.04608,
     "end_time": "2021-03-11T18:12:54.308988",
     "exception": false,
     "start_time": "2021-03-11T18:12:54.262908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #the following line gives ~10% speedup\n",
    "    #but may lead to some stochasticity in the results \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010988,
     "end_time": "2021-03-11T18:12:54.330833",
     "exception": false,
     "start_time": "2021-03-11T18:12:54.319845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data\n",
    "One important thing here is the train/val split. To avoid possible leaks resulted by a similarity of tiles from the same images, it is better to keep tiles from each image together in train or in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.057765,
     "end_time": "2021-03-11T18:12:54.40978",
     "exception": false,
     "start_time": "2021-03-11T18:12:54.352015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/thedevastator/hubmap-2022-256x256\n",
    "mean = np.array([0.7720342, 0.74582646, 0.76392896])\n",
    "std = np.array([0.24745085, 0.26182273, 0.25782376])\n",
    "\n",
    "def img2tensor(img,dtype:np.dtype=np.float32):\n",
    "    if img.ndim==2 : img = np.expand_dims(img,2)\n",
    "    img = np.transpose(img,(2,0,1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False))\n",
    "\n",
    "class HuBMAPDataset(Dataset):\n",
    "    def __init__(self, train=True, tfms=None):\n",
    "        ids = pd.read_csv(LABELS).id.astype(str).values\n",
    "        if train:\n",
    "            ids = train_ids\n",
    "        else:\n",
    "            ids = val_ids\n",
    "\n",
    "        self.fnames = [fname for fname in os.listdir(TRAIN) if fname.split('_')[0] in ids or int(fname.split('_')[0]) in ids]\n",
    "        self.train = train\n",
    "        self.tfms = tfms\n",
    "        print(\"number of files\", len(self.fnames))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        img = cv2.cvtColor(cv2.imread(os.path.join(TRAIN,fname)), cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(os.path.join(MASKS,fname),cv2.IMREAD_GRAYSCALE)\n",
    "        if self.tfms is not None:\n",
    "            augmented = self.tfms(image=img,mask=mask)\n",
    "            img,mask = augmented['image'],augmented['mask']\n",
    "        return img2tensor((img/255.0 - mean)/std),img2tensor(mask)\n",
    "    \n",
    "def get_aug(p=1.0):\n",
    "    return Compose([\n",
    "        HorizontalFlip(),\n",
    "        VerticalFlip(),\n",
    "        RandomRotate90(),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=0.9, \n",
    "                         border_mode=cv2.BORDER_REFLECT),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.3),\n",
    "        OneOf([\n",
    "            HueSaturationValue(10,15,10),\n",
    "            CLAHE(clip_limit=2),\n",
    "            RandomBrightnessContrast(),            \n",
    "        ], p=0.3),\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 12.580982,
     "end_time": "2021-03-11T18:13:07.001785",
     "exception": false,
     "start_time": "2021-03-11T18:12:54.420803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #example of train images with masks\n",
    "# ds = HuBMAPDataset(tfms=get_aug())\n",
    "# dl = DataLoader(ds,batch_size=BATCH_SIZE,shuffle=False,num_workers=NUM_WORKERS)\n",
    "# print(len(dl))\n",
    "# imgs,masks = next(iter(dl))\n",
    "\n",
    "# plt.figure(figsize=(16,16))\n",
    "# for i,(img,mask) in enumerate(zip(imgs,masks)):\n",
    "#     img = ((img.permute(1,2,0)*std + mean)*255.0).numpy().astype(np.uint8)\n",
    "#     plt.subplot(8,8,i+1)\n",
    "#     plt.imshow(img,vmin=0,vmax=255)\n",
    "#     plt.imshow(mask.squeeze().numpy(), alpha=0.2)\n",
    "#     plt.axis('off')\n",
    "#     plt.subplots_adjust(wspace=None, hspace=None)\n",
    "    \n",
    "# del ds,dl,imgs,masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041669,
     "end_time": "2021-03-11T18:13:07.084926",
     "exception": false,
     "start_time": "2021-03-11T18:13:07.043257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "The model used in this kernel is based on a U-shape network (UneXt50, see image below), which I used in Severstal and Understanding Clouds competitions. The idea of a U-shape network is coming from a [Unet](https://arxiv.org/pdf/1505.04597.pdf) architecture proposed in 2015 for medical images: the encoder part creates a representation of features at different levels, while the decoder combines the features and generates a prediction as a segmentation mask. The skip connections between encoder and decoder allow us to utilize features from the intermediate conv layers of the encoder effectively, without a need for the information to go the full way through entire encoder and decoder. The latter is especially important to link the predicted mask to the specific pixels of the detected object. Later people realized that ImageNet pretrained computer vision models could drastically improve the quality of a segmentation model because of optimized architecture of the encoder, high encoder capacity (in contrast to one used in the original Unet), and the power of the transfer learning.\n",
    "\n",
    "There are several important things that must be added to a Unet network, however, to make it able to reach competitive results with current state of the art approaches. First, it is **Feature Pyramid Network (FPN)**: additional skip connection between different upscaling blocks of the decoder and the output layer. So, the final prediction is produced based on the concatenation of U-net output with resized outputs of the intermediate layers. These skip-connections provide a shortcut for gradient flow improving model performance and convergence speed. Since intermediate layers have many channels, their upscaling and use as an input for the final layer would introduce a significant overhead in terms of the computational time and memory. Therefore, 3x3+3x3 convolutions are applied (factorization) before the resize to reduce the number of channels.\n",
    "\n",
    "Another very important thing is the **Atrous Spatial Pyramid Pooling (ASPP) block** added between encoder and decoder. The flaw of the traditional U-shape networks is resulted by a small receptive field. Therefore, if a model needs to make a decision about a segmentation of a large object, especially for a large image resolution, it can get confused being able to look only into parts of the object. A way to increase the receptive field and enable interactions between different parts of the image is use of a block combining convolutions with different dilatations ([Atrous convolutions](https://arxiv.org/pdf/1606.00915.pdf) with various rates in ASPP block). While the original paper uses 6,12,18 rates, they may be customized for a particular task and a particular image resolution to maximize the performance. One more thing I added is using group convolutions in ASPP block to reduce the number of model parameters.\n",
    "\n",
    "Finally, the decoder upscaling blocks are based on [pixel shuffle](https://arxiv.org/pdf/1609.05158.pdf) rather than transposed convolution used in the first Unet models. It allows to avoid artifacts in the produced masks. And I use [semisupervised Imagenet pretrained ResNeXt50](https://github.com/facebookresearch/semi-supervised-ImageNet1K-models) model as a backbone. In Pytorch it provides the performance of EfficientNet B2-B3 with much faster convergence for the computational cost and GPU RAM requirements of EfficientNet B0 (though, in TF EfficientNet is highly optimized and may be a good thing to use)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04012,
     "end_time": "2021-03-11T18:13:07.166112",
     "exception": false,
     "start_time": "2021-03-11T18:13:07.125992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://i.ibb.co/z5KxDzm/Une-Xt50-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.110724,
     "end_time": "2021-03-11T18:13:07.317006",
     "exception": false,
     "start_time": "2021-03-11T18:13:07.206282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    def __init__(self, input_channels:list, output_channels:list):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Sequential(nn.Conv2d(in_ch, out_ch*2, kernel_size=3, padding=1),\n",
    "             nn.ReLU(inplace=True), nn.BatchNorm2d(out_ch*2),\n",
    "             nn.Conv2d(out_ch*2, out_ch, kernel_size=3, padding=1))\n",
    "            for in_ch, out_ch in zip(input_channels, output_channels)])\n",
    "        \n",
    "    def forward(self, xs:list, last_layer):\n",
    "        hcs = [F.interpolate(c(x),scale_factor=2**(len(self.convs)-i),mode='bilinear') \n",
    "               for i,(c,x) in enumerate(zip(self.convs, xs))]\n",
    "        hcs.append(last_layer)\n",
    "        return torch.cat(hcs, dim=1)\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in_c:int, x_in_c:int, nf:int=None, blur:bool=False,\n",
    "                 self_attention:bool=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(x_in_c)\n",
    "        ni = up_in_c//2 + x_in_c\n",
    "        nf = nf if nf is not None else max(up_in_c//2,32)\n",
    "        self.conv1 = ConvLayer(ni, nf, norm_type=None, **kwargs)\n",
    "        self.conv2 = ConvLayer(nf, nf, norm_type=None,\n",
    "            xtra=SelfAttention(nf) if self_attention else None, **kwargs)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, up_in:Tensor, left_in:Tensor) -> Tensor:\n",
    "        s = left_in\n",
    "        up_out = self.shuf(up_in)\n",
    "        cat_x = self.relu(torch.cat([up_out, self.bn(s)], dim=1))\n",
    "        return self.conv2(self.conv1(cat_x))\n",
    "        \n",
    "class _ASPPModule(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size, padding, dilation, groups=1):\n",
    "        super().__init__()\n",
    "        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                stride=1, padding=padding, dilation=dilation, bias=False, groups=groups)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_conv(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, inplanes=512, mid_c=256, dilations=[6, 12, 18, 24], out_c=None):\n",
    "        super().__init__()\n",
    "        self.aspps = [_ASPPModule(inplanes, mid_c, 1, padding=0, dilation=1)] + \\\n",
    "            [_ASPPModule(inplanes, mid_c, 3, padding=d, dilation=d,groups=4) for d in dilations]\n",
    "        self.aspps = nn.ModuleList(self.aspps)\n",
    "        self.global_pool = nn.Sequential(nn.AdaptiveMaxPool2d((1, 1)),\n",
    "                        nn.Conv2d(inplanes, mid_c, 1, stride=1, bias=False),\n",
    "                        nn.BatchNorm2d(mid_c), nn.ReLU())\n",
    "        out_c = out_c if out_c is not None else mid_c\n",
    "        self.out_conv = nn.Sequential(nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False),\n",
    "                                    nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))\n",
    "        self.conv1 = nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False)\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.global_pool(x)\n",
    "        xs = [aspp(x) for aspp in self.aspps]\n",
    "        x0 = F.interpolate(x0, size=xs[0].size()[2:], mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x0] + xs, dim=1)\n",
    "        return self.out_conv(x)\n",
    "    \n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.152684,
     "end_time": "2021-03-11T18:13:07.526419",
     "exception": false,
     "start_time": "2021-03-11T18:13:07.373735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UneXt50(nn.Module):\n",
    "    def __init__(self, stride=1, **kwargs):\n",
    "        super().__init__()\n",
    "        #encoder\n",
    "        m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models',\n",
    "                           'resnext50_32x4d_ssl')\n",
    "        self.enc0 = nn.Sequential(m.conv1, m.bn1, nn.ReLU(inplace=True))\n",
    "        self.enc1 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "                            m.layer1) #256\n",
    "        self.enc2 = m.layer2 #512\n",
    "        self.enc3 = m.layer3 #1024\n",
    "        self.enc4 = m.layer4 #2048\n",
    "        #aspp with customized dilatations\n",
    "        self.aspp = ASPP(2048,256,out_c=512,dilations=[stride*1,stride*2,stride*3,stride*4])\n",
    "        self.drop_aspp = nn.Dropout2d(0.5)\n",
    "        #decoder\n",
    "        self.dec4 = UnetBlock(512,1024,256)\n",
    "        self.dec3 = UnetBlock(256,512,128)\n",
    "        self.dec2 = UnetBlock(128,256,64)\n",
    "        self.dec1 = UnetBlock(64,64,32)\n",
    "        self.fpn = FPN([512,256,128,64],[16]*4)\n",
    "        self.drop = nn.Dropout2d(0.1)\n",
    "        self.final_conv = ConvLayer(32+16*4, 1, ks=1, norm_type=None, act_cls=None)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        enc0 = self.enc0(x)\n",
    "        enc1 = self.enc1(enc0)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        enc5 = self.aspp(enc4)\n",
    "        dec3 = self.dec4(self.drop_aspp(enc5),enc3)\n",
    "        dec2 = self.dec3(dec3,enc2)\n",
    "        dec1 = self.dec2(dec2,enc1)\n",
    "        dec0 = self.dec1(dec1,enc0)\n",
    "        x = self.fpn([enc5, dec3, dec2, dec1], dec0)\n",
    "        x = self.final_conv(self.drop(x))\n",
    "        x = F.interpolate(x,scale_factor=2,mode='bilinear')\n",
    "        return x\n",
    "\n",
    "#split the model to encoder and decoder for fast.ai\n",
    "split_layers = lambda m: [list(m.enc0.parameters())+list(m.enc1.parameters())+\n",
    "                list(m.enc2.parameters())+list(m.enc3.parameters())+\n",
    "                list(m.enc4.parameters()),\n",
    "                list(m.aspp.parameters())+list(m.dec4.parameters())+\n",
    "                list(m.dec3.parameters())+list(m.dec2.parameters())+\n",
    "                list(m.dec1.parameters())+list(m.fpn.parameters())+\n",
    "                list(m.final_conv.parameters())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.076542,
     "end_time": "2021-03-11T18:13:07.688572",
     "exception": false,
     "start_time": "2021-03-11T18:13:07.61203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss and metric\n",
    "A famous loss for image segmentation is the [Lovász loss](https://arxiv.org/pdf/1705.08790.pdf), a surrogate of IoU. Following [iafoss](https://www.kaggle.com/iafoss)'s [work](https://www.kaggle.com/code/iafoss/hubmap-pytorch-fast-ai-starter):\n",
    "- **ReLU in it must be replaced by (ELU + 1)**(, like he did [here](https://www.kaggle.com/iafoss/lovasz).\n",
    "- **Symmetric Lovász loss:** consider not only a predicted segmentation and a provided mask but also the inverse prediction and the inverse mask (predict mask for negative case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.125886,
     "end_time": "2021-03-11T18:13:07.88963",
     "exception": false,
     "start_time": "2021-03-11T18:13:07.763744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def symmetric_lovasz(outputs, targets):\n",
    "    return 0.5*(lovasz_hinge(outputs, targets) + lovasz_hinge(-outputs, 1.0 - targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.090188,
     "end_time": "2021-03-11T18:13:08.037967",
     "exception": false,
     "start_time": "2021-03-11T18:13:07.947779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dice_soft(Metric):\n",
    "    def __name__(self, ):\n",
    "        return \"Dice soft\"\n",
    "    \n",
    "    def __init__(self, axis=1): \n",
    "        self.axis = axis \n",
    "        self.inter = 0.0\n",
    "        self.union = 0\n",
    "        \n",
    "    def reset(self): self.inter,self.union = 0,0\n",
    "    def accumulate(self, preds, gts):\n",
    "        pred,targ = flatten_check(torch.sigmoid(preds), gts)\n",
    "        self.inter += (pred*targ).float().sum().item()\n",
    "        self.union += (pred+targ).float().sum().item()\n",
    "    \n",
    "    @property\n",
    "    def value(self): return 2.0 * self.inter/self.union if self.union > 0 else None\n",
    "    \n",
    "# dice with automatic threshold selection\n",
    "class Dice_th(Metric):\n",
    "    def __name__(self, ):\n",
    "        return \"Dice th\"\n",
    "    \n",
    "    def __init__(self, ths=np.arange(0.1,0.9,0.05), axis=1): \n",
    "        self.axis = axis\n",
    "        self.ths = ths\n",
    "        self.inter = torch.zeros(len(self.ths))\n",
    "        self.union = torch.zeros(len(self.ths))\n",
    "    \n",
    "    def reset(self): \n",
    "        self.inter = torch.zeros(len(self.ths))\n",
    "        self.union = torch.zeros(len(self.ths))\n",
    "        \n",
    "    def accumulate(self, preds, gts):\n",
    "        pred,targ = flatten_check(torch.sigmoid(preds), gts)\n",
    "        for i,th in enumerate(self.ths):\n",
    "            p = (pred > th).float()\n",
    "            self.inter[i] += (p*targ).float().sum().item()\n",
    "            self.union[i] += (p+targ).float().sum().item()\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        dices = torch.where(self.union > 0.0, \n",
    "                2.0*self.inter/self.union, torch.zeros_like(self.union))\n",
    "        return dices.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040333,
     "end_time": "2021-03-11T18:13:08.119299",
     "exception": false,
     "start_time": "2021-03-11T18:13:08.078966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.095878,
     "end_time": "2021-03-11T18:13:08.255835",
     "exception": false,
     "start_time": "2021-03-11T18:13:08.159957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#iterator like wrapper that returns predicted and gt masks\n",
    "class Model_pred:\n",
    "    def __init__(self, model, dl, tta:bool=True, half:bool=False):\n",
    "        self.model = model\n",
    "        self.dl = dl\n",
    "        self.tta = tta\n",
    "        self.half = half\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.model.eval()\n",
    "        name_list = self.dl.dataset.fnames\n",
    "        count=0\n",
    "        with torch.no_grad():\n",
    "            for x,y in iter(self.dl):\n",
    "                x = x.cuda()\n",
    "                if self.half: x = x.half()\n",
    "                p = self.model(x)\n",
    "                py = torch.sigmoid(p).detach()\n",
    "                if self.tta:\n",
    "                    #x,y,xy flips as TTA\n",
    "                    flips = [[-1],[-2],[-2,-1]]\n",
    "                    for f in flips:\n",
    "                        p = self.model(torch.flip(x,f))\n",
    "                        p = torch.flip(p,f)\n",
    "                        py += torch.sigmoid(p).detach()\n",
    "                    py /= (1+len(flips))\n",
    "                if y is not None and len(y.shape)==4 and py.shape != y.shape:\n",
    "                    py = F.upsample(py, size=(y.shape[-2],y.shape[-1]), mode=\"bilinear\")\n",
    "                py = py.permute(0,2,3,1).float().cpu()\n",
    "                batch_size = len(py)\n",
    "                for i in range(batch_size):\n",
    "                    taget = y[i].detach().cpu() if y is not None else None\n",
    "                    yield py[i],taget,name_list[count]\n",
    "                    count += 1\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.dl.dataset)\n",
    "    \n",
    "class Dice_th_pred(Metric):\n",
    "    def __init__(self, ths=np.arange(0.1,0.9,0.01), axis=1): \n",
    "        self.axis = axis\n",
    "        self.ths = ths\n",
    "        self.inter = torch.zeros(len(self.ths))\n",
    "        self.union = torch.zeros(len(self.ths))\n",
    "        \n",
    "    def reset(self): \n",
    "        self.inter = torch.zeros(len(self.ths))\n",
    "        self.union = torch.zeros(len(self.ths))\n",
    "        \n",
    "    def accumulate(self,p,t):\n",
    "        pred,targ = flatten_check(p, t)\n",
    "        for i,th in enumerate(self.ths):\n",
    "            p = (pred > th).float()\n",
    "            self.inter[i] += (p*targ).float().sum().item()\n",
    "            self.union[i] += (p+targ).float().sum().item()\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        dices = torch.where(self.union > 0.0, 2.0*self.inter/self.union, \n",
    "                            torch.zeros_like(self.union))\n",
    "        return dices\n",
    "    \n",
    "def save_img(data,name,out):\n",
    "    data = data.float().cpu().numpy()\n",
    "    img = cv2.imencode('.png',(data*255).astype(np.uint8))[1]\n",
    "    out.writestr(name, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040885,
     "end_time": "2021-03-11T18:13:08.336994",
     "exception": false,
     "start_time": "2021-03-11T18:13:08.296109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "    from segmentation_models_pytorch import utils as smp_utils\n",
    "except Exception as e:\n",
    "    !pip install segmentation_models_pytorch\n",
    "    import segmentation_models_pytorch as smp\n",
    "    from segmentation_models_pytorch import utils as smp_utils\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageValueMeter():\n",
    "    def __init__(self):\n",
    "        super(AverageValueMeter, self).__init__()\n",
    "        self.reset()\n",
    "        self.val = 0\n",
    "\n",
    "    def add(self, value, n=1):\n",
    "        self.val = value\n",
    "        self.sum += value\n",
    "        self.var += value * value\n",
    "        self.n += n\n",
    "\n",
    "        if self.n == 0:\n",
    "            self.mean, self.std = np.nan, np.nan\n",
    "        elif self.n == 1:\n",
    "            self.mean = 0.0 + self.sum  # This is to force a copy in torch/numpy\n",
    "            self.std = np.inf\n",
    "            self.mean_old = self.mean\n",
    "            self.m_s = 0.0\n",
    "        else:\n",
    "            self.mean = self.mean_old + (value - n * self.mean_old) / float(self.n)\n",
    "            self.m_s += (value - self.mean_old) * (value - self.mean)\n",
    "            self.mean_old = self.mean\n",
    "            self.std = np.sqrt(self.m_s / (self.n - 1.0))\n",
    "\n",
    "    def value(self):\n",
    "        return self.mean, self.std\n",
    "\n",
    "    def reset(self):\n",
    "        self.n = 0\n",
    "        self.sum = 0.0\n",
    "        self.var = 0.0\n",
    "        self.val = 0.0\n",
    "        self.mean = np.nan\n",
    "        self.mean_old = 0.0\n",
    "        self.m_s = 0.0\n",
    "        self.std = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, loss_fn, metrics):\n",
    "    logs = {}\n",
    "    loss_meter = AverageValueMeter()\n",
    "    metrics_meters = {metric.__name__(): AverageValueMeter() for metric in metrics}\n",
    "\n",
    "    for idx, (imgs, masks) in enumerate(tqdm(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        imgs, masks = imgs.cuda(), masks.cuda()\n",
    "        preds = model(imgs)\n",
    "        loss = loss_fn(preds, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update loss logs\n",
    "        loss_value = loss.cpu().detach().numpy()\n",
    "        loss_meter.add(loss_value)\n",
    "        loss_logs = {\"loss\": loss_meter.mean}\n",
    "        logs.update(loss_logs)\n",
    "\n",
    "                \n",
    "        # update metrics logs\n",
    "        for metric_fn in metrics:\n",
    "            metric_fn.accumulate(preds, masks)\n",
    "            metric_value = metric_fn.value\n",
    "            metrics_meters[metric_fn.__name__()].add(metric_value)\n",
    "        metrics_logs = {k: v.mean for k, v in metrics_meters.items()}\n",
    "        logs.update(metrics_logs)\n",
    "    return logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(model, dataloader, optimizer, loss_fn, metrics):\n",
    "    \n",
    "    logs = {}\n",
    "    loss_meter = AverageValueMeter()\n",
    "    metrics_meters = {metric.__name__(): AverageValueMeter() for metric in metrics}\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    for idx, (imgs, masks) in enumerate(tqdm(dataloader)):\n",
    "        imgs, masks = imgs.cuda(), masks.cuda()\n",
    "        preds = model(imgs)\n",
    "        loss = loss_fn(preds, masks)\n",
    "        \n",
    "        loss_value = loss.cpu().detach().numpy()\n",
    "\n",
    "        # update loss logs\n",
    "        loss_value = loss.cpu().detach().numpy()\n",
    "        loss_meter.add(loss_value)\n",
    "        loss_logs = {\"loss\": loss_meter.mean}\n",
    "\n",
    "        logs.update(loss_logs)\n",
    "\n",
    "                \n",
    "        # update metrics logs\n",
    "        for metric_fn in metrics:\n",
    "            metric_fn.accumulate(preds, masks)\n",
    "            metric_value = metric_fn.value\n",
    "            metrics_meters[metric_fn.__name__()].add(metric_value)\n",
    "        metrics_logs = {k: v.mean for k, v in metrics_meters.items()}\n",
    "        logs.update(metrics_logs)\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\TAI NGUYEN TRONG/.cache\\torch\\hub\\facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    }
   ],
   "source": [
    "model = UneXt50().cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[Dice_soft(),Dice_th()]\n",
    "optimizer = torch.optim.SGD([ \n",
    "    dict(params=model.parameters(), lr=0.00001),\n",
    "])\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 29637.81713,
     "end_time": "2021-03-12T02:27:06.195179",
     "exception": false,
     "start_time": "2021-03-11T18:13:08.378049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files 2367\n",
      "number of files 424\n",
      "\n",
      "Epoch: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:54<00:00,  3.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5851234646639065 133\n",
      "\n",
      "Epoch: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:34<00:00,  3.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5853279679226614 134\n",
      "\n",
      "Epoch: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:26<00:00,  4.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5859865464579768 135\n",
      "\n",
      "Epoch: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:26<00:00,  4.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.587518582640736 136\n",
      "\n",
      "Epoch: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:29<00:00,  3.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5879052828153788 137\n",
      "\n",
      "Epoch: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:24<00:00,  4.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:33<00:00,  3.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:24<00:00,  4.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5886873921677428 140\n",
      "\n",
      "Epoch: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:32<00:00,  3.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5891072532838548 141\n",
      "\n",
      "Epoch: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:24<00:00,  4.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5895839640334362 142\n",
      "\n",
      "Epoch: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:25<00:00,  4.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5900991864444268 143\n",
      "\n",
      "Epoch: 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:31<00:00,  3.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5909471657052777 144\n",
      "\n",
      "Epoch: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:28<00:00,  3.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5915164442270809 145\n",
      "\n",
      "Epoch: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5918056653715336 146\n",
      "\n",
      "Epoch: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5922987917561363 147\n",
      "\n",
      "Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5928499385638123 148\n",
      "\n",
      "Epoch: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:30<00:00,  3.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5932337412746437 149\n",
      "\n",
      "Epoch: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:32<00:00,  3.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5938269212036732 150\n",
      "\n",
      "Epoch: 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:29<00:00,  3.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5944013492324891 151\n",
      "\n",
      "Epoch: 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:31<00:00,  3.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5950234386259915 152\n",
      "\n",
      "Epoch: 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.595335745574243 153\n",
      "\n",
      "Epoch: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:26<00:00,  4.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5959048104336817 154\n",
      "\n",
      "Epoch: 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:29<00:00,  3.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5965524639249509 155\n",
      "\n",
      "Epoch: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:25<00:00,  4.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5970452221198703 156\n",
      "\n",
      "Epoch: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.597627869985054 157\n",
      "\n",
      "Epoch: 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5981844305560936 158\n",
      "\n",
      "Epoch: 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:32<00:00,  3.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5985805635696003 159\n",
      "\n",
      "Epoch: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:29<00:00,  3.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5990382990795342 160\n",
      "\n",
      "Epoch: 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:29<00:00,  3.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.5995913315027482 161\n",
      "\n",
      "Epoch: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6000091746391141 162\n",
      "\n",
      "Epoch: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:28<00:00,  3.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6005760194786108 163\n",
      "\n",
      "Epoch: 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:24<00:00,  4.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.601130006158964 164\n",
      "\n",
      "Epoch: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:25<00:00,  4.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6015450334801528 165\n",
      "\n",
      "Epoch: 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:26<00:00,  4.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6020968694163813 166\n",
      "\n",
      "Epoch: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:43<00:00,  3.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6026046234071876 167\n",
      "\n",
      "Epoch: 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:48<00:00,  3.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6031292811525762 168\n",
      "\n",
      "Epoch: 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:43<00:00,  3.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:11<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6036215610111599 169\n",
      "\n",
      "Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:45<00:00,  3.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6042229151988014 170\n",
      "\n",
      "Epoch: 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:49<00:00,  3.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6047666906544111 171\n",
      "\n",
      "Epoch: 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:00<00:00,  3.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:12<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6053537068423575 172\n",
      "\n",
      "Epoch: 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:12<00:00,  3.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:12<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6059506562761734 173\n",
      "\n",
      "Epoch: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:48<00:00,  3.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6063882087198151 174\n",
      "\n",
      "Epoch: 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:49<00:00,  3.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.606872136870081 175\n",
      "\n",
      "Epoch: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:49<00:00,  3.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6074831294030668 176\n",
      "\n",
      "Epoch: 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:43<00:00,  3.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6079310933324716 177\n",
      "\n",
      "Epoch: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:46<00:00,  3.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6083873705600645 178\n",
      "\n",
      "Epoch: 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:43<00:00,  3.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6088377827652781 179\n",
      "\n",
      "Epoch: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:57<00:00,  3.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6093404488658124 180\n",
      "\n",
      "Epoch: 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:48<00:00,  3.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6098302746820349 181\n",
      "\n",
      "Epoch: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:47<00:00,  3.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6102871548175353 182\n",
      "\n",
      "Epoch: 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:55<00:00,  3.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6107655499074902 183\n",
      "\n",
      "Epoch: 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:48<00:00,  3.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6113174314289445 184\n",
      "\n",
      "Epoch: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:37<00:00,  3.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6118286974479549 185\n",
      "\n",
      "Epoch: 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:28<00:00,  4.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6122904739955803 186\n",
      "\n",
      "Epoch: 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:28<00:00,  3.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6127583386039342 187\n",
      "\n",
      "Epoch: 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:42<00:00,  3.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:16<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6131956331394512 188\n",
      "\n",
      "Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:49<00:00,  2.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6136408118302767 189\n",
      "\n",
      "Epoch: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:15<00:00,  3.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:11<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6139676544314883 190\n",
      "\n",
      "Epoch: 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:48<00:00,  3.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6144550855251426 191\n",
      "\n",
      "Epoch: 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:34<00:00,  3.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6149265321283878 192\n",
      "\n",
      "Epoch: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:38<00:00,  3.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6153896605103719 193\n",
      "\n",
      "Epoch: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:34<00:00,  3.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.61578090911764 194\n",
      "\n",
      "Epoch: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:32<00:00,  3.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6163469440603909 195\n",
      "\n",
      "Epoch: 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:31<00:00,  3.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6168935802441176 196\n",
      "\n",
      "Epoch: 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:28<00:00,  3.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6173605169036076 197\n",
      "\n",
      "Epoch: 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:29<00:00,  3.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6178043486863648 198\n",
      "\n",
      "Epoch: 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:30<00:00,  3.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 12.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6182411734952907 199\n",
      "\n",
      "Epoch: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:36<00:00,  3.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6187148171975033 200\n",
      "\n",
      "Epoch: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:35<00:00,  3.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6191480058723337 201\n",
      "\n",
      "Epoch: 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:31<00:00,  3.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6195876827131095 202\n",
      "\n",
      "Epoch: 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6200536520849319 203\n",
      "\n",
      "Epoch: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6205340884576417 204\n",
      "\n",
      "Epoch: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:30<00:00,  3.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6210369721197759 205\n",
      "\n",
      "Epoch: 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:28<00:00,  3.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6214640129559377 206\n",
      "\n",
      "Epoch: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:27<00:00,  4.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6219326692120296 207\n",
      "\n",
      "Epoch: 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:30<00:00,  3.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.62239152319587 208\n",
      "\n",
      "Epoch: 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:28<00:00,  4.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:07<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6228429792740767 209\n",
      "\n",
      "Epoch: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:35<00:00,  3.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 12.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.623294743276949 210\n",
      "\n",
      "Epoch: 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:38<00:00,  3.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6237225098411688 211\n",
      "\n",
      "Epoch: 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:44<00:00,  3.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:11<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6241325081129743 212\n",
      "\n",
      "Epoch: 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:49<00:00,  3.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6245684720970345 213\n",
      "\n",
      "Epoch: 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:56<00:00,  3.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:12<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6249815954880626 214\n",
      "\n",
      "Epoch: 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:55<00:00,  3.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:11<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.625440380206259 215\n",
      "\n",
      "Epoch: 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:03<00:00,  3.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6259487973870874 216\n",
      "\n",
      "Epoch: 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:03<00:00,  3.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6264095046335768 217\n",
      "\n",
      "Epoch: 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:12<00:00,  3.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6268488391439794 218\n",
      "\n",
      "Epoch: 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:49<00:00,  3.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6272440099756343 219\n",
      "\n",
      "Epoch: 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:52<00:00,  3.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:11<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6276370579801239 220\n",
      "\n",
      "Epoch: 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:58<00:00,  3.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6280570629900258 221\n",
      "\n",
      "Epoch: 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:57<00:00,  3.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6284493965334055 222\n",
      "\n",
      "Epoch: 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:43<00:00,  3.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.628869317662131 223\n",
      "\n",
      "Epoch: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:46<00:00,  3.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6292870288665429 224\n",
      "\n",
      "Epoch: 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:59<00:00,  3.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6296503734501772 225\n",
      "\n",
      "Epoch: 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:57<00:00,  3.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:14<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6300793039222278 226\n",
      "\n",
      "Epoch: 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:51<00:00,  3.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6304922409564823 227\n",
      "\n",
      "Epoch: 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:56<00:00,  3.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6309063415603108 228\n",
      "\n",
      "Epoch: 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:49<00:00,  3.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:09<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6313214183639295 229\n",
      "\n",
      "Epoch: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:46<00:00,  3.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6317136716464844 230\n",
      "\n",
      "Epoch: 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:51<00:00,  3.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6320931221134023 231\n",
      "\n",
      "Epoch: 232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:01<00:00,  3.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6324999830082475 232\n",
      "\n",
      "Epoch: 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:53<00:00,  3.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6329082864824608 233\n",
      "\n",
      "Epoch: 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [02:43<00:00,  3.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:08<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6332844838411178 234\n",
      "\n",
      "Epoch: 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:09<00:00,  3.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:17<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6337199537317996 235\n",
      "\n",
      "Epoch: 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:54<00:00,  2.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:13<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6341148453247223 236\n",
      "\n",
      "Epoch: 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:55<00:00,  2.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:16<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6345109451221012 237\n",
      "\n",
      "Epoch: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:56<00:00,  2.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:15<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6349003477948834 238\n",
      "\n",
      "Epoch: 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:51<00:00,  2.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:16<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6352773215199016 239\n",
      "\n",
      "Epoch: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:15<00:00,  3.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:10<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6355985718748591 240\n",
      "\n",
      "Epoch: 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:24<00:00,  2.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:12<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6359585539214978 241\n",
      "\n",
      "Epoch: 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:28<00:00,  2.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:13<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6362951412898468 242\n",
      "\n",
      "Epoch: 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:50<00:00,  2.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:14<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6366704592867132 243\n",
      "\n",
      "Epoch: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:50<00:00,  2.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:13<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.637029699725543 244\n",
      "\n",
      "Epoch: 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 592/592 [03:29<00:00,  2.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [00:13<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! 0.6373816755353007 245\n",
      "\n",
      "Epoch: 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████                          | 400/592 [02:33<01:13,  2.61it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.50 MiB for an array with shape (256, 256, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m133\u001b[39m, \u001b[38;5;241m400\u001b[39m):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[1;32m---> 15\u001b[0m     train_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymmetric_lovasz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     valid_logs \u001b[38;5;241m=\u001b[39m val_one_epoch(model, val_dataloader, optimizer, symmetric_lovasz, metrics)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# do something (save model, change lr, etc.)\u001b[39;00m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, optimizer, loss_fn, metrics)\u001b[0m\n\u001b[0;32m      3\u001b[0m loss_meter \u001b[38;5;241m=\u001b[39m AverageValueMeter()\n\u001b[0;32m      4\u001b[0m metrics_meters \u001b[38;5;241m=\u001b[39m {metric\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m(): AverageValueMeter() \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics}\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (imgs, masks) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(dataloader)):\n\u001b[0;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      8\u001b[0m     imgs, masks \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mcuda(), masks\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\envs\\work_env\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\envs\\work_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\envs\\work_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\envs\\work_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\envs\\work_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mHuBMAPDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     31\u001b[0m     augmented \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtfms(image\u001b[38;5;241m=\u001b[39mimg,mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m     32\u001b[0m     img,mask \u001b[38;5;241m=\u001b[39m augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m],augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img2tensor((\u001b[43mimg\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m255.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m)\u001b[38;5;241m/\u001b[39mstd),img2tensor(mask)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.50 MiB for an array with shape (256, 256, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "dice = Dice_th(np.arange(0.2,0.7,0.1))\n",
    "\n",
    "train_dataset = HuBMAPDataset(train=True, tfms=get_aug())\n",
    "val_dataset = HuBMAPDataset(train=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "            num_workers=NUM_WORKERS, drop_last=False, pin_memory=True, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "            num_workers=NUM_WORKERS, drop_last=False, pin_memory=True, shuffle=False)\n",
    "max_score = 0.0\n",
    "\n",
    "num_plataue_epoch = 0\n",
    "\n",
    "for epoch in range(0, 250):\n",
    "    print('\\nEpoch: {}'.format(epoch))\n",
    "    train_logs = train_one_epoch(model, train_dataloader, optimizer, symmetric_lovasz, metrics)\n",
    "    valid_logs = val_one_epoch(model, val_dataloader, optimizer, symmetric_lovasz, metrics)\n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['Dice soft']:\n",
    "        max_score = valid_logs['Dice soft']\n",
    "        model_info = \"_{}_{}_{}.pth\".format(epoch,BATCH_SIZE, round(max_score, 4))\n",
    "        save_model = SAVE_FILE+model_info\n",
    "        torch.save(model, save_model)\n",
    "        print('Model saved at', save_model)\n",
    "    else:\n",
    "        num_plataue_epoch += 1\n",
    "    if epoch == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')\n",
    "    if num_plataue_epoch == 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
